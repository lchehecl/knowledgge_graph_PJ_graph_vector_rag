# graph_rag.py â€”â€” ä½¿ç”¨ sentence-transformers + prompt æ¨¡å¼
import json
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from typing import List, Dict, Any
import torch

class TmiGraphRAG:
    def __init__(self, jsonl_path: str):
        self.nodes = []
        self.relationships = []
        self.node_id_to_index = {}
        self.node_embeddings = None
        self._load_graph(jsonl_path)
        self._build_embeddings()
        self._init_embedding_model()  # â† å»¶ååŠ è½½æ¨¡å‹

    def _load_graph(self, path: str):
        print("ğŸ“¥ æ­£åœ¨åŠ è½½ graph_data.jsonl ...")
        with open(path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    obj = json.loads(line.strip())
                    if obj["type"] == "node":
                        self.nodes.append(obj)
                        self.node_id_to_index[obj["id"]] = len(self.nodes) - 1
                    elif obj["type"] == "relationship":
                        self.relationships.append(obj)
                except Exception as e:
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆè¡Œ: {e}")
        print(f"âœ… åŠ è½½å®Œæˆ: {len(self.nodes)} ä¸ªèŠ‚ç‚¹, {len(self.relationships)} æ¡å…³ç³»")

    def _parse_embedding(self, emb):
        if emb is None:
            return None
        if isinstance(emb, str):
            try:
                emb = json.loads(emb.replace("'", '"').replace("array(", "[").replace(")", "]"))
            except:
                return None
        if isinstance(emb, list):
            return np.array(emb, dtype=np.float32)
        return None

    def _build_embeddings(self):
        print("ğŸ§® æ­£åœ¨æ„å»ºèŠ‚ç‚¹ embedding çŸ©é˜µ...")
        embeddings = []
        valid_indices = []
        for i, node in enumerate(self.nodes):
            emb = self._parse_embedding(node["properties"].get("embedding"))
            if emb is not None and emb.size > 0:
                embeddings.append(emb)
                valid_indices.append(i)
            else:
                print(f"âš ï¸ èŠ‚ç‚¹ {node['id']} ç¼ºå°‘æœ‰æ•ˆ embeddingï¼Œè·³è¿‡")

        if not embeddings:
            raise ValueError("æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆ embeddingï¼è¯·æ£€æŸ¥ graph_data.jsonl")

        self.node_embeddings = np.stack(embeddings)
        old_nodes = self.nodes
        self.nodes = [old_nodes[i] for i in valid_indices]
        self.node_id_to_index = {node["id"]: idx for idx, node in enumerate(self.nodes)}
        print(f"âœ… æ„å»ºå®Œæˆ: {self.node_embeddings.shape[0]} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹, ç»´åº¦ {self.node_embeddings.shape[1]}")

    def _init_embedding_model(self):
        # Lazy load: ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶æ‰åŠ è½½
        if not hasattr(self, '_model'):
            print("â³ é¦–æ¬¡åŠ è½½ SentenceTransformer('BAAI/bge-multilingual-gemma2')...")
            from sentence_transformers import SentenceTransformer

             # ğŸ” é…ç½®é‡è¯•ï¼šæœ€å¤š 5 æ¬¡ï¼ŒæŒ‡æ•°é€€é¿
            retry_kwargs = {
            "max_retries": 5,
            "backoff_factor": 1.5,
            }
            
            self._model = SentenceTransformer(
                "BAAI/bge-m3",
                model_kwargs={"torch_dtype": torch.float16},
                device="cuda" if torch.cuda.is_available() else "cpu",
                trust_remote_code=True,
            )
            from huggingface_hub import configure_http_backend
            import requests
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry

            retry_strategy = Retry(
                total=5,
                backoff_factor=1,
                status_forcelist=[429, 500, 502, 503, 504],
            )
            adapter = HTTPAdapter(max_retries=retry_strategy)
            http = requests.Session()
            http.mount("https://", adapter)
            http.mount("http://", adapter)
            configure_http_backend(http)

            # ğŸ”‘ å…³é”®ï¼šè®¾ç½®ç»Ÿä¸€çš„ promptï¼ˆä¸ä½ å½“åˆç”Ÿæˆ node embedding æ—¶ä¸€è‡´ï¼ï¼‰
            # ä½ å½“åˆæ„å»º graph_data.jsonl æ—¶ç”¨çš„ä»€ä¹ˆ promptï¼Ÿå¿…é¡»å®Œå…¨ä¸€è‡´ï¼
            # æ ¹æ®ä½ çš„æ ·ä¾‹ï¼Œå¾ˆå¯èƒ½æ˜¯ï¼š
            self._instruction = "Given a scientific query about medical imaging, retrieve relevant papers, methods, or tasks."
            self._prompt = f'<instruct>{self._instruction}\n<query>'
            print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œprompt = '{self._prompt[:50]}...'")
    
    def _text_to_query_embedding(self, text: str) -> np.ndarray:
        self._init_embedding_model()  # ç¡®ä¿å·²åŠ è½½
        # ğŸ”‘ ä½¿ç”¨ **ç›¸åŒ prompt** encodeï¼
        embedding = self._model.encode(
            [text],  # æ³¨æ„ï¼šencode è¦æ±‚ list
            prompt=self._prompt,
            convert_to_numpy=True,
            normalize_embeddings=True  # å¯é€‰ï¼Œä½†æ¨èï¼ˆæå‡ cosine ç›¸ä¼¼åº¦ç¨³å®šæ€§ï¼‰
        )[0]
        return embedding.astype(np.float32)

    def retrieve_nodes_by_embedding(self, query: str, top_k: int = 5) -> List[Dict]:
        query_emb = self._text_to_query_embedding(query)
        if query_emb.shape[0] != self.node_embeddings.shape[1]:
            raise ValueError(
                f"ç»´åº¦ä¸åŒ¹é…ï¼Query: {query_emb.shape[0]} â‰  Nodes: {self.node_embeddings.shape[1]}\n"
                "è¯·ç¡®è®¤ï¼š1) node embedding ä¹Ÿæ˜¯ç”¨ bge-multilingual-gemma2 + ç›¸åŒ prompt ç”Ÿæˆï¼›2) æ²¡æœ‰åå¤„ç†ï¼ˆå¦‚ PCAï¼‰"
            )
        sims = cosine_similarity([query_emb], self.node_embeddings)[0]
        top_idxs = np.argsort(sims)[-top_k:][::-1]
        results = []
        for i in top_idxs:
            if sims[i] > 0.2:  # é™ä½é˜ˆå€¼ï¼Œé¿å…æ¼å¬
                results.append(self.nodes[i])
        return results
    
    def get_neighbors(self, node_id: str) -> List[Dict]:
        neighbors = []
        for rel in self.relationships:
            if rel["start_node_id"] == node_id:
                other_id = rel["end_node_id"]
            elif rel["end_node_id"] == node_id:
                other_id = rel["start_node_id"]
            else:
                continue
            idx = self.node_id_to_index.get(other_id)
            if idx is not None:
                neighbors.append({
                    "relationship": rel["label"],
                    "node": self.nodes[idx]
                })
        return neighbors

    def rag_context(self, question: str, top_k_nodes: int = 3) -> str:
        retrieved = self.retrieve_nodes_by_embedding(question, top_k=top_k_nodes)
        lines = []
        for node in retrieved:
            props = node["properties"]
            label = node["labels"][0] if node["labels"] else "Node"
            if label == "Paper":
                title = props.get("title", "N/A")
                year = props.get("year", "N/A")
                paper_id = props.get("paper_id", "N/A")
                lines.append(f"ğŸ“„ è®ºæ–‡: ã€Š{title}ã€‹ (ID: {paper_id}, å¹´ä»½: {year})")
                # åŠ ä¸€è·³é‚»å±…
                for nb in self.get_neighbors(node["id"]):
                    nb_node = nb["node"]
                    nb_label = nb_node["labels"][0] if nb_node["labels"] else "Node"
                    nb_props = nb_node["properties"]
                    if nb_label == "Task":
                        lines.append(f"   â†’ ç ”ç©¶ä»»åŠ¡: {nb_props.get('name', 'N/A')}")
                    elif nb_label == "Method":
                        lines.append(f"   â†’ æå‡ºæ–¹æ³•: {nb_props.get('name', 'N/A')}")
                    elif nb_label == "ImagingModality":
                        lines.append(f"   â†’ ä½¿ç”¨æ¨¡æ€: {nb_props.get('name', 'N/A')}")
            elif label in ["Task", "ImagingModality", "Method", "AnatomicalStructure"]:
                name = props.get("name", "N/A")
                lines.append(f"ğŸ·ï¸ {label}: {name} (ID: {props.get('id', 'N/A')})")
        return "\n".join(lines) if lines else "(æ— ç›¸å…³èŠ‚ç‚¹)"
    # ...ï¼ˆget_neighbors å’Œ rag_context ä¿æŒä¸å˜ï¼Œç•¥ï¼‰
